<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://pranavra0.github.io/images/favicon.png" />
<title>Project1 | ...</title>
<meta name="title" content="Project1" />
<meta name="description" content="NOTE: the Jupyter Notebook link contains all the code used to generate visuals as well as the data cleaning
Jupyer Notebok
Dataset Link
The Problem
Originally, I wanted to do a heart attack dataset and I got to work using one. As I was searching for trends I realized &hellip; there were none! The whole dataset was entirely synthetic everything being randomly generated. A sedentary 65&#43; year old had the same chance of a heart attack as a 20 year old who is physically active. As I continued searching I came to the realization that nearly all the heart attack datasets that the search showed were synthetic. So I went back to the drawing board and decided it would be interesting to see what datasets end up being successful on Kaggle. Why did the Kaggle algorithm show me this dataset that was fabricated? Was it because it had an inordinate number of tags? Or was it something else?" />
<meta name="keywords" content="" />


<meta property="og:url" content="https://pranavra0.github.io/project1/">
  <meta property="og:site_name" content="...">
  <meta property="og:title" content="Project1">
  <meta property="og:description" content="NOTE: the Jupyter Notebook link contains all the code used to generate visuals as well as the data cleaning
Jupyer Notebok
Dataset Link
The Problem Originally, I wanted to do a heart attack dataset and I got to work using one. As I was searching for trends I realized … there were none! The whole dataset was entirely synthetic everything being randomly generated. A sedentary 65&#43; year old had the same chance of a heart attack as a 20 year old who is physically active. As I continued searching I came to the realization that nearly all the heart attack datasets that the search showed were synthetic. So I went back to the drawing board and decided it would be interesting to see what datasets end up being successful on Kaggle. Why did the Kaggle algorithm show me this dataset that was fabricated? Was it because it had an inordinate number of tags? Or was it something else?">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-01-31T09:10:09-05:00">
    <meta property="article:modified_time" content="2025-01-31T09:10:09-05:00">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Project1">
  <meta name="twitter:description" content="NOTE: the Jupyter Notebook link contains all the code used to generate visuals as well as the data cleaning
Jupyer Notebok
Dataset Link
The Problem Originally, I wanted to do a heart attack dataset and I got to work using one. As I was searching for trends I realized … there were none! The whole dataset was entirely synthetic everything being randomly generated. A sedentary 65&#43; year old had the same chance of a heart attack as a 20 year old who is physically active. As I continued searching I came to the realization that nearly all the heart attack datasets that the search showed were synthetic. So I went back to the drawing board and decided it would be interesting to see what datasets end up being successful on Kaggle. Why did the Kaggle algorithm show me this dataset that was fabricated? Was it because it had an inordinate number of tags? Or was it something else?">




  <meta itemprop="name" content="Project1">
  <meta itemprop="description" content="NOTE: the Jupyter Notebook link contains all the code used to generate visuals as well as the data cleaning
Jupyer Notebok
Dataset Link
The Problem Originally, I wanted to do a heart attack dataset and I got to work using one. As I was searching for trends I realized … there were none! The whole dataset was entirely synthetic everything being randomly generated. A sedentary 65&#43; year old had the same chance of a heart attack as a 20 year old who is physically active. As I continued searching I came to the realization that nearly all the heart attack datasets that the search showed were synthetic. So I went back to the drawing board and decided it would be interesting to see what datasets end up being successful on Kaggle. Why did the Kaggle algorithm show me this dataset that was fabricated? Was it because it had an inordinate number of tags? Or was it something else?">
  <meta itemprop="datePublished" content="2025-01-31T09:10:09-05:00">
  <meta itemprop="dateModified" content="2025-01-31T09:10:09-05:00">
  <meta itemprop="wordCount" content="902">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  :root {
      --width: 800px;
      --font-main: Times New Roman, serif;
      --font-secondary: Times, serif;
      --font-scale: 1.1em;
      --background-color: #fff;
      --heading-color: #222;
      --text-color: #444;
      --link-color: #3273dc;
      --visited-color:  #8b6fcb;
      --code-background-color: #ffffff;
      --code-color: #f8f8f2;
      --blockquote-color: #222;
  }

  @media (prefers-color-scheme: dark) {
    :root {
        --background-color: #09090b;
        --heading-color: #ffffff;
        --text-color: #cccccc;
        --link-color: #7abfff;
        --visited-color: #b693f9;
        --code-background-color: #2e2e3e;
        --code-color: #f8f8f2;
        --blockquote-color: #bbbbbb;
    }
}

  body {
      font-family: var(--font-secondary);
      font-size: var(--font-scale);
      margin: auto;
      padding: 20px;
      max-width: var(--width);
      text-align: left;
      background-color: var(--background-color);
      word-wrap: break-word;
      overflow-wrap: break-word;
      line-height: 1.5;
      color: var(--text-color);
  }

  h1, h2, h3, h4, h5, h6 {
      font-family: var(--font-main);
      color: var(--heading-color);
      font-style: italic;   
  }

  a {
      color: var(--link-color);
      cursor: pointer;
      text-decoration: none;
  }

  a:hover {
      text-decoration: underline; 
  }

  nav a {
      margin-right: 8px;
  }

  strong, b {
      color: var(--heading-color);
  }

  button {
      margin: 0;
      cursor: pointer;
  }

  main {
      line-height: 1.6;
  }

  table {
      width: 100%;
  }

  hr {
      border: 0;
      border-top: 1px dashed;
  }

  img {
      max-width: 100%;
  }

  code {
    font-family: 'Fira Code', monospace;
    background-color: var(--code-background-color);
    color: var(--code-color);
    border-radius: 6px;
    font-size: 0.95em;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.5);
    padding: 0;  
    margin: 0px;  
    outline: 2px dashed #999;  
    outline-offset: 4px;  
}


  blockquote {
      border-left: 1px solid #999;
      color: var(--blockquote-color);
      padding-left: 20px;
      font-style: italic;
  }

  footer {
      padding: 25px 0;
      text-align: center;
  }

  .title:hover {
      text-decoration: none;
  }

  .title h1 {
      font-size: 1.5em;
  }

  .inline {
      width: auto !important;
  }

    .highlight .keyword, .code .keyword {
        color: #ff79c6;
        font-weight: bold;
    }

    .highlight .string, .code .string {
        color: #f1fa8c;
    }

    .highlight .comment, .code .comment {
        color: #6272a4;
        font-style: italic;
    }

    .highlight .number, .code .number {
        color: #bd93f9;
    }

   
  ul.blog-posts {
      list-style-type: none;
      padding: unset;
  }

  ul.blog-posts li {
      display: flex;
  }

  ul.blog-posts li span {
      flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
      color: var(--visited-color);
  }
</style>

</head>

<body>
  <header><a href="/" class="title">
  <h2>...</h2>
</a>
<nav><a href="/">Home</a>


<a href="/blog">Blog</a>

</nav>
</header>
  <main>

<h1>Project1</h1>
<p>
  <i>
    <time datetime='2025-01-31'>
      2025-01-31
    </time>
  </i>
</p>

<content>
  <p><strong>NOTE: the Jupyter Notebook link contains all the code used to generate visuals as well as the data cleaning</strong></p>
<p><a href="/notebooks/project1.html">Jupyer Notebok</a></p>
<p><a href="https://www.kaggle.com/datasets/canggih/voted-kaggle-dataset">Dataset Link</a></p>
<h1 id="the-problem">The Problem</h1>
<p>Originally, I wanted to do a heart attack dataset and I got to work using one. As I was searching for trends I realized &hellip; there were none! The whole dataset was entirely synthetic everything being randomly generated. A sedentary 65+ year old had the same chance of a heart attack as a 20 year old who is physically active. As I continued searching I came to the realization that <em>nearly all</em> the heart attack datasets that the search showed were synthetic. So I went back to the drawing board and decided it would be interesting to see what datasets end up being successful on Kaggle. Why did the Kaggle algorithm show me this dataset that was fabricated? Was it because it had an inordinate number of tags? Or was it something else?</p>
<p>Through this project, I will be aiming to find some clear trends in Kaggle&rsquo;s algorithm and what drives a dataset to be popular. Additionally, I would like to find out what might make a dataset unpopular. Hopefully, by the end of this, I will have a clearer idea of what exactly caused me to be shown so much synthetic data.</p>
<h1 id="introduction-to-the-data">Introduction to the Data</h1>
<p>The dataset includes 15 columns detailing various attributes such as:</p>
<ul>
<li>title</li>
<li>owner</li>
<li>votes</li>
<li>tags</li>
<li>data type</li>
<li>size</li>
<li>engagement metrics (views, downloads, and kernels)</li>
</ul>
<p>Additionally, it features a little over 2k individual rows to examine.</p>
<h1 id="preprocessing">Preprocessing</h1>
<p>There was quite a bit of preprocessing to be done due how statistical data was labelled. For example the views column was formatted as &ldquo;<code>number</code> views&rdquo; so converting it to a set of integers by removing the appended &ldquo;views&rdquo; was needed. This was done for the Downloads column as well. I had some help with ChatGPT specifically for parsing and replacing the strings. I repeated this process for Downloads, Topics, and Kernels.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;Views&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Views&#39;</span>]<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39;,&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>)<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#39; views&#39;</span>, <span style="color:#e6db74">&#39;&#39;</span>)
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;Views&#39;</span>] <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>to_numeric(df[<span style="color:#e6db74">&#39;Views&#39;</span>], errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;coerce&#39;</span>)
</span></span><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;Views&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Views&#39;</span>]<span style="color:#f92672">.</span>fillna(df[<span style="color:#e6db74">&#39;Views&#39;</span>]<span style="color:#f92672">.</span>median()) 
</span></span></code></pre></div><p>After replacing these values with the median, I also went about clearing out some of the NA values in tags column. This would make it be easier to create visualizations later on. Given how the Kaggle API works, it is likely these fields were simply empty at the time the datasets were published.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;Tags&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Tags&#39;</span>]<span style="color:#f92672">.</span>fillna(<span style="color:#e6db74">&#39;No Tags&#39;</span>)
</span></span></code></pre></div><p>Another feature I ended up adding is the <code>Num_Tags</code> column which opens up the ability to look at some other potential relationships in the data</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>df[<span style="color:#e6db74">&#39;Num_Tags&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;Tags&#39;</span>]<span style="color:#f92672">.</span>apply(<span style="color:#66d9ef">lambda</span> x: len(str(x)<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)))
</span></span></code></pre></div><p>With that the dataset is in a state where I can easily generate some visuals and begin the process of trying to answer some of the questions that were posed at the start.</p>
<p><em>Quick note: I ended up ignoring NA subtitles as I don&rsquo;t really plan to use that col at all for this project</em></p>
<h1 id="visualizations--story">Visualizations // Story</h1>
<p>So what about the first question? Well, the number of tags doesn&rsquo;t seem to matter at all.</p>
<p><img src="/images/project1/viewstags.png" alt="viewstags"></p>
<p>One thing that immediately stood out to me was just how outlier-ey the outliers were. To get a better look I made the chart below. It shows just about exactly what we would expect but also demonstrates just how much attention goes to just a few datasets.</p>
<p><img src="/images/project1/corrviewsdownloads.png" alt="corrviewsdownloads"></p>
<p>After seeing this I decided to take a look at the distributions for datasets. How are dataset views/downloads distributed, exactly? Well it matches pretty well with what the previous charts showed. It is massively unequal with the <em>vast majority</em> of views going to just a couple datasets.</p>
<p><img src="/images/project1/distofviewsanddownloads.png" alt="distofviewsanddownloads"></p>
<p>At this point I was interested to see if any other features showed interesting correlations. I ended up making some for kernels, topics, and file size.</p>
<p>Kernels show a pretty significant correlation with views but once again we see just how far out the outliers are.</p>
<p>Interestingly, it wasn&rsquo;t the amount of tags that mattered as much as the amount of topics. This might be why those fake heart attack datasets were so popular. They were absolutely full of topics and that seems to help. Those outlier datasets I have mentioned so far have a massive amount of topics in comparison to the rest of the group.</p>
<p><img src="/images/project1/kernelsvviews.png" alt="kernelsvviews"></p>
<p>Interestingly, it wasn&rsquo;t the amount of tags that mattered as much as the amount of topics. This might be why those fake heart attack datasets were so popular. They were absolutely full of topics and that seems to help. Those outlier datasets I have mentioned so far have a massive amount of topics in comparison to the rest of the group.</p>
<p><img src="/images/project1/viewstopics.png" alt="viewstopics"></p>
<p>I was a bit surprised by the file size results. There is a pretty significant peak for the smallest of datasets and, once again, you see the outliers doing what they do. Despite that peak, there seems to be a pretty uniform, though sparse, distribution of views even as the size gets larger.
<img src="/images/project1/filesizeviews.png" alt="filesizeviews"></p>
<hr>
<p>So, if I was interested in creating a super popular dataset what would I do? Nothing seems to matter too much, to be entirely honest. Just given this data, you are better of creating as many as possible and hoping at least one of them becomes one of those outliers. And, if I were to guess, that is exactly why Kaggle has so many synthetic data sets for cardiovascular diseases. They are easy to make and increase the chance of getting a &ldquo;hit.&rdquo;</p>

</content>
<p>
  
</p>

  </main>
  <footer>
</footer>

    
</body>

</html>
